{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf cartpoleg0.99.tar.gz cartpoleg0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BC - behaviour clonging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('data_Ohio.csv', delimiter=',', skip_header = 1)\n",
    "my_data = my_data[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array([np.concatenate([my_data[t], my_data[t + 1], my_data[t + 2], my_data[t + 3][:3]]) for t in range(6600 - 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array([my_data[t + 3][3] for t in range(6600 - 4)])\n",
    "actions = actions.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _RL.behavior_cloning as bc\n",
    "ohio_bc = bc.BehaviorCloning(num_actions=5, S_dims = 15, depth = 2,\n",
    "                 hidden_dims = 32, activation='relu',\n",
    "                 lr=5e-4, decay_steps=100000,\n",
    "                 batch_size=64, max_epoch=200, \n",
    "                 validation_split=0.2, patience=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(sampler)\n",
    "RB = sampler.SimpleReplayBuffer(trajs_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19920, 15)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RB.states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19920, 15)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RB.states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "83/83 [==============================] - 0s 4ms/step - loss: 113.5269 - accuracy: 0.0775 - val_loss: 15.0826 - val_accuracy: 0.2182\n",
      "Epoch 2/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 12.7351 - accuracy: 0.6531 - val_loss: 8.2764 - val_accuracy: 0.6788\n",
      "Epoch 3/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 9.3292 - accuracy: 0.6840 - val_loss: 5.6529 - val_accuracy: 0.6333\n",
      "Epoch 4/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 6.8621 - accuracy: 0.6920 - val_loss: 4.2638 - val_accuracy: 0.6902\n",
      "Epoch 5/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 5.1136 - accuracy: 0.7056 - val_loss: 3.4733 - val_accuracy: 0.6667\n",
      "Epoch 6/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 3.9508 - accuracy: 0.7060 - val_loss: 3.0851 - val_accuracy: 0.6621\n",
      "Epoch 7/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 3.2434 - accuracy: 0.7121 - val_loss: 2.8149 - val_accuracy: 0.7091\n",
      "Epoch 8/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.8152 - accuracy: 0.7189 - val_loss: 2.4455 - val_accuracy: 0.7326\n",
      "Epoch 9/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.4838 - accuracy: 0.7214 - val_loss: 2.3393 - val_accuracy: 0.7364\n",
      "Epoch 10/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.2627 - accuracy: 0.7314 - val_loss: 2.1796 - val_accuracy: 0.6917\n",
      "Epoch 11/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 2.1154 - accuracy: 0.7293 - val_loss: 2.0417 - val_accuracy: 0.7235\n",
      "Epoch 12/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.9789 - accuracy: 0.7303 - val_loss: 1.9457 - val_accuracy: 0.7242\n",
      "Epoch 13/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.8580 - accuracy: 0.7367 - val_loss: 1.7153 - val_accuracy: 0.7295\n",
      "Epoch 14/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.7529 - accuracy: 0.7377 - val_loss: 1.5789 - val_accuracy: 0.7167\n",
      "Epoch 15/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.6607 - accuracy: 0.7415 - val_loss: 1.7405 - val_accuracy: 0.7568\n",
      "Epoch 16/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.5761 - accuracy: 0.7477 - val_loss: 1.4957 - val_accuracy: 0.7439\n",
      "Epoch 17/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4962 - accuracy: 0.7511 - val_loss: 1.4223 - val_accuracy: 0.7311\n",
      "Epoch 18/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.4211 - accuracy: 0.7564 - val_loss: 1.2545 - val_accuracy: 0.7576\n",
      "Epoch 19/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.3383 - accuracy: 0.7568 - val_loss: 1.2019 - val_accuracy: 0.7568\n",
      "Epoch 20/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.2712 - accuracy: 0.7633 - val_loss: 1.1702 - val_accuracy: 0.7250\n",
      "Epoch 21/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.2115 - accuracy: 0.7659 - val_loss: 1.1345 - val_accuracy: 0.7318\n",
      "Epoch 22/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.1401 - accuracy: 0.7701 - val_loss: 1.0203 - val_accuracy: 0.7485\n",
      "Epoch 23/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0965 - accuracy: 0.7691 - val_loss: 1.0305 - val_accuracy: 0.7652\n",
      "Epoch 24/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0389 - accuracy: 0.7767 - val_loss: 1.0037 - val_accuracy: 0.7462\n",
      "Epoch 25/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 1.0019 - accuracy: 0.7786 - val_loss: 0.9386 - val_accuracy: 0.7561\n",
      "Epoch 26/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9609 - accuracy: 0.7805 - val_loss: 0.9057 - val_accuracy: 0.7568\n",
      "Epoch 27/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9297 - accuracy: 0.7794 - val_loss: 0.8845 - val_accuracy: 0.7795\n",
      "Epoch 28/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.9050 - accuracy: 0.7841 - val_loss: 0.9660 - val_accuracy: 0.7712\n",
      "Epoch 29/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.8612 - accuracy: 0.7906 - val_loss: 0.9336 - val_accuracy: 0.7470\n",
      "Epoch 30/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.8557 - accuracy: 0.7889 - val_loss: 0.8645 - val_accuracy: 0.7765\n",
      "Epoch 31/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.8250 - accuracy: 0.7906 - val_loss: 0.8289 - val_accuracy: 0.7788\n",
      "Epoch 32/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.8175 - accuracy: 0.7976 - val_loss: 0.7666 - val_accuracy: 0.7985\n",
      "Epoch 33/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.7876 - accuracy: 0.8002 - val_loss: 0.8046 - val_accuracy: 0.7909\n",
      "Epoch 34/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.7751 - accuracy: 0.8000 - val_loss: 0.8354 - val_accuracy: 0.7894\n",
      "Epoch 35/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.7573 - accuracy: 0.8008 - val_loss: 0.7888 - val_accuracy: 0.7841\n",
      "Epoch 36/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.7607 - accuracy: 0.8046 - val_loss: 0.8169 - val_accuracy: 0.7932\n",
      "Epoch 37/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.7518 - accuracy: 0.8038 - val_loss: 0.7322 - val_accuracy: 0.7917\n",
      "Epoch 38/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.7154 - accuracy: 0.8095 - val_loss: 0.7278 - val_accuracy: 0.7932\n",
      "Epoch 39/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.8108 - val_loss: 0.6960 - val_accuracy: 0.7962\n",
      "Epoch 40/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.7281 - accuracy: 0.8093 - val_loss: 0.8829 - val_accuracy: 0.7985\n",
      "Epoch 41/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.7104 - accuracy: 0.8127 - val_loss: 0.7144 - val_accuracy: 0.7886\n",
      "Epoch 42/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.8118 - val_loss: 0.7875 - val_accuracy: 0.7955\n",
      "Epoch 43/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.8120 - val_loss: 0.7402 - val_accuracy: 0.7841\n",
      "Epoch 44/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6889 - accuracy: 0.8177 - val_loss: 0.7558 - val_accuracy: 0.7977\n",
      "Epoch 45/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.8179 - val_loss: 0.6650 - val_accuracy: 0.7985\n",
      "Epoch 46/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.8169 - val_loss: 0.6927 - val_accuracy: 0.7924\n",
      "Epoch 47/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.8163 - val_loss: 0.6839 - val_accuracy: 0.7955\n",
      "Epoch 48/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.8179 - val_loss: 0.7070 - val_accuracy: 0.8000\n",
      "Epoch 49/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.8213 - val_loss: 0.6835 - val_accuracy: 0.7985\n",
      "Epoch 50/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6765 - accuracy: 0.8169 - val_loss: 0.6530 - val_accuracy: 0.7970\n",
      "Epoch 51/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.8186 - val_loss: 0.6950 - val_accuracy: 0.7970\n",
      "Epoch 52/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6881 - accuracy: 0.8194 - val_loss: 0.6687 - val_accuracy: 0.7970\n",
      "Epoch 53/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6694 - accuracy: 0.8175 - val_loss: 0.7498 - val_accuracy: 0.7932\n",
      "Epoch 54/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6719 - accuracy: 0.8171 - val_loss: 0.6488 - val_accuracy: 0.7970\n",
      "Epoch 55/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.8211 - val_loss: 0.6770 - val_accuracy: 0.7992\n",
      "Epoch 56/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.8197 - val_loss: 0.7255 - val_accuracy: 0.8045\n",
      "Epoch 57/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.8216 - val_loss: 0.6772 - val_accuracy: 0.7977\n",
      "Epoch 58/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.8209 - val_loss: 0.6703 - val_accuracy: 0.8030\n",
      "Epoch 59/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.8220 - val_loss: 0.7910 - val_accuracy: 0.8008\n",
      "Epoch 60/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6441 - accuracy: 0.8218 - val_loss: 0.6875 - val_accuracy: 0.7962\n",
      "Epoch 61/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6366 - accuracy: 0.8224 - val_loss: 0.8346 - val_accuracy: 0.7992\n",
      "Epoch 62/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.8224 - val_loss: 0.7784 - val_accuracy: 0.8015\n",
      "Epoch 63/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.8192 - val_loss: 0.8719 - val_accuracy: 0.8106\n",
      "Epoch 64/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.8213 - val_loss: 0.7168 - val_accuracy: 0.8023\n",
      "Epoch 65/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.8220 - val_loss: 0.6821 - val_accuracy: 0.7917\n",
      "Epoch 66/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.8209 - val_loss: 0.7441 - val_accuracy: 0.7932\n",
      "Epoch 67/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.8222 - val_loss: 0.6954 - val_accuracy: 0.8000\n",
      "Epoch 68/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.8213 - val_loss: 0.6929 - val_accuracy: 0.8023\n",
      "Epoch 69/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6371 - accuracy: 0.8241 - val_loss: 0.6604 - val_accuracy: 0.8114\n",
      "Epoch 70/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.8228 - val_loss: 0.6364 - val_accuracy: 0.8061\n",
      "Epoch 71/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.8215 - val_loss: 0.6974 - val_accuracy: 0.7985\n",
      "Epoch 72/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.8243 - val_loss: 0.6385 - val_accuracy: 0.8091\n",
      "Epoch 73/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6271 - accuracy: 0.8254 - val_loss: 0.6614 - val_accuracy: 0.7886\n",
      "Epoch 74/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.8232 - val_loss: 0.7182 - val_accuracy: 0.7886\n",
      "Epoch 75/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.8230 - val_loss: 0.6563 - val_accuracy: 0.8083\n",
      "Epoch 76/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.8213 - val_loss: 0.6577 - val_accuracy: 0.8008\n",
      "Epoch 77/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6519 - accuracy: 0.8220 - val_loss: 0.6428 - val_accuracy: 0.8000\n",
      "Epoch 78/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.8226 - val_loss: 0.6233 - val_accuracy: 0.8000\n",
      "Epoch 79/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.8224 - val_loss: 0.6799 - val_accuracy: 0.8023\n",
      "Epoch 80/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.8230 - val_loss: 0.6864 - val_accuracy: 0.8053\n",
      "Epoch 81/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.8232 - val_loss: 0.8109 - val_accuracy: 0.7894\n",
      "Epoch 82/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.8228 - val_loss: 0.6972 - val_accuracy: 0.7939\n",
      "Epoch 83/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.8218 - val_loss: 0.7015 - val_accuracy: 0.7962\n",
      "Epoch 84/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6110 - accuracy: 0.8252 - val_loss: 0.6276 - val_accuracy: 0.7977\n",
      "Epoch 85/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.8243 - val_loss: 0.8649 - val_accuracy: 0.7886\n",
      "Epoch 86/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.8230 - val_loss: 0.7391 - val_accuracy: 0.7939\n",
      "Epoch 87/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.8205 - val_loss: 0.8437 - val_accuracy: 0.7970\n",
      "Epoch 88/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.8270 - val_loss: 0.6382 - val_accuracy: 0.8061\n",
      "Epoch 89/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.8266 - val_loss: 0.5998 - val_accuracy: 0.7924\n",
      "Epoch 90/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.8247 - val_loss: 0.6612 - val_accuracy: 0.8000\n",
      "Epoch 91/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.8251 - val_loss: 0.7268 - val_accuracy: 0.7962\n",
      "Epoch 92/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.8247 - val_loss: 0.6633 - val_accuracy: 0.7955\n",
      "Epoch 93/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.8251 - val_loss: 0.6514 - val_accuracy: 0.8114\n",
      "Epoch 94/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.8232 - val_loss: 0.7001 - val_accuracy: 0.7932\n",
      "Epoch 95/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6157 - accuracy: 0.8264 - val_loss: 0.7093 - val_accuracy: 0.7879\n",
      "Epoch 96/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6095 - accuracy: 0.8230 - val_loss: 0.6028 - val_accuracy: 0.7977\n",
      "Epoch 97/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.8199 - val_loss: 0.8334 - val_accuracy: 0.7962\n",
      "Epoch 98/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.8218 - val_loss: 0.6610 - val_accuracy: 0.8015\n",
      "Epoch 99/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.8266 - val_loss: 0.6079 - val_accuracy: 0.8053\n",
      "Epoch 100/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.8249 - val_loss: 0.6386 - val_accuracy: 0.8008\n",
      "Epoch 101/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6050 - accuracy: 0.8258 - val_loss: 0.6512 - val_accuracy: 0.8008\n",
      "Epoch 102/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.8260 - val_loss: 0.6740 - val_accuracy: 0.8023\n",
      "Epoch 103/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.8264 - val_loss: 0.6383 - val_accuracy: 0.8091\n",
      "Epoch 104/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.8264 - val_loss: 0.6079 - val_accuracy: 0.7985\n",
      "Epoch 105/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6086 - accuracy: 0.8254 - val_loss: 0.6268 - val_accuracy: 0.8008\n",
      "Epoch 106/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.8245 - val_loss: 0.6186 - val_accuracy: 0.8000\n",
      "Epoch 107/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6001 - accuracy: 0.8279 - val_loss: 0.6103 - val_accuracy: 0.8068\n",
      "Epoch 108/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.8260 - val_loss: 0.6722 - val_accuracy: 0.7970\n",
      "Epoch 109/200\n",
      "83/83 [==============================] - 0s 3ms/step - loss: 0.6173 - accuracy: 0.8247 - val_loss: 0.6925 - val_accuracy: 0.7932\n"
     ]
    }
   ],
   "source": [
    "ohio_bc.train(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "As = ohio_bc.get_A(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.31e+03, 0.00e+00, 3.00e+00, 0.00e+00, 0.00e+00, 9.40e+01,\n",
       "        0.00e+00, 1.87e+02, 0.00e+00, 2.00e+00]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist(As)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

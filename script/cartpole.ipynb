{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _util import *\n",
    "import _RL.FQE as FQE_module\n",
    "import _RL.FQI as FQI\n",
    "import _RL.my_gym as my_gym\n",
    "import _TRIPLE as TRIPLE\n",
    "import _analyze as analyze\n",
    "import _RL.DQN as DQN\n",
    "import _RL.my_gym as my_gym\n",
    "import _cartpole as cartpole\n",
    "reload(cartpole)\n",
    "reload(my_gym)\n",
    "\n",
    "reload(TRIPLE)\n",
    "reload(analyze)\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "tf.keras.backend.set_floatx('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N = 10, T = 300, tau = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "unique_setting = \"cart_w_Q\"\n",
    "N = 10\n",
    "\n",
    "n_gpu = 8\n",
    "\n",
    "rep = 200\n",
    "tau = 0.3\n",
    "T = 300\n",
    "data_exist = 0\n",
    "env = cartpole.CartPoleEnv(e_max = 1000, std = 0.01)\n",
    "\n",
    "########################################################################\n",
    "gamma = .98\n",
    "init_Q_ratio = 0.99\n",
    "incomplete_ratio = 20\n",
    "FQE_paras = {\"verbose\" : 1, \"test_freq\" : 50\n",
    "             , \"eps\" : 0.0001, \"max_iter\" : 200, \"init_Q_ratio\" : init_Q_ratio\n",
    "             , \"max_depth\" : 20, \"n_estimators\" : 1000, \"min_samples_leaf\" : 10\n",
    "             ,  \"use_RF\" : 1}\n",
    "################################################################################################################################################ \n",
    "###################################################### Default Settings ######################################################\n",
    "################################################################################################################################################\n",
    "hyperparameters = [N, T, gamma, tau, init_Q_ratio, incomplete_ratio]\n",
    "################## estimate the target policy [fixed number of iterations?] ##################\n",
    "setting = EST()[7:9] + EST()[10:13]+ \"_\"  + unique_setting + \"_\" + \"N\" + str(N) + \"_\" + \"T\" + str(T) + \"_\" + \"initQ\" + str(init_Q_ratio) + \"_\"  + \"tau\" + \"_\" + str(tau)\n",
    "printR(\"setting: {}\".format(setting))\n",
    "################################################################################################################## \n",
    "weight_path = \"target_policies/\" + \"cartpole\" + \"g\" + str(0.99)\n",
    "tp_path = weight_path + \"/iter\" + str(20000)\n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "###################\n",
    "if data_exist:\n",
    "    data = load(\"data/\" + Q_file)\n",
    "    trajs_train_resp = data['trajs_train_resp']\n",
    "    V_true = data['V_true']\n",
    "    init_S = data['init_S']\n",
    "    print(\"V_true = {:.3f}\".format(V_true))\n",
    "else:\n",
    "    pi1 = DQN.DQN_gym(num_states = 4, num_actions = 2\n",
    "                      , hidden_units = [256, 256], gamma = gamma\n",
    "                      , gpu_number = 0)\n",
    "    pi1.model.load_weights(tp_path)\n",
    "    #########################################################\n",
    "    pi_behav = my_gym.softmax_policy(pi1, tau)\n",
    "\n",
    "    gym_eval = my_gym.GymEval(random_pi = True)\n",
    "    trajs = gym_eval.simu_trajs_para(pi_behav, rep = 10000, burn_in = 500)\n",
    "    init_S = gym_eval.get_init_S_from_trajs(trajs, n_init = 1000) # use in estimation\n",
    "    # \n",
    "    init_S_4_eval = gym_eval.get_init_S_from_trajs(trajs, n_init = 10000)\n",
    "    V_true = gym_eval.eval_policy(pi = pi1, gamma = gamma, init_states = init_S_4_eval, rep = len(init_S_4_eval))\n",
    "    #\n",
    "    trajs = gym_eval.simu_trajs_para(pi_behav, rep = N * rep * 2, burn_in = 500)\n",
    "    trajs_train_resp = [trajs[(i * N):((i + 1) * N)] for i in range(rep)]\n",
    "    data = {\"trajs_train_resp\" : trajs_train_resp\n",
    "           , \"V_true\" : V_true\n",
    "           , \"init_S\" : init_S}\n",
    "    dump(data, \"data/\" + Q_file)\n",
    "\n",
    "    \n",
    "##################################################################################################################\n",
    "##################################################################################################################\n",
    "ray.shutdown()\n",
    "a = now()\n",
    "rec = analyze.recorder()\n",
    "rec.hyper = hyperparameters\n",
    "for i in range(rep // n_gpu):\n",
    "    traj_this_rep = [trajs_train_resp[i] for i in range(n_gpu * i, n_gpu * (i + 1))]\n",
    "    @ray.remote(num_gpus=1)\n",
    "    def one_seed1(seed):\n",
    "        tf.keras.backend.set_floatx('float32')\n",
    "        gpu_idx = seed % n_gpu\n",
    "        pi1 = DQN.DQN_gym(num_states = 4, num_actions = 2\n",
    "                  , hidden_units = [256, 256], gamma = gamma\n",
    "                  , gpu_number = gpu_idx)\n",
    "        pi1.model.load_weights(tp_path)\n",
    "        trajs_train = traj_this_rep[gpu_idx]\n",
    "        ############################ TRIPLE to estimate values ############################\n",
    "        are = TRIPLE.ARE(trajs_train, pi = pi1, gamma = gamma, gpu_number = gpu_idx, incomplete_ratio = incomplete_ratio, L = 2\n",
    "                        , sepe_A = True)\n",
    "        are.init_S = init_S \n",
    "        are.est_Q(**FQE_paras)\n",
    "#         are.load_Q(Q_values = Qs[seed])\n",
    "        are.est_w(h_dims = 512, batch_size = 256, lr = 0.001, print_freq = 300, tolerance = 10, max_iter = 500, rep_loss = 5)\n",
    "        are.est_IS()\n",
    "        are.est_double_robust()\n",
    "        #######\n",
    "        are.est_cond_w(h_dims = 512, batch_size = 32, lr = 0.0001, print_freq = 300, tolerance = 10, max_iter = 500, rep_loss = 5)\n",
    "        are.est_triply_robust()  \n",
    "        are.est_quad_robust()\n",
    "        #######\n",
    "        # analyze.recorder().print_one_seed(V_true, are)\n",
    "        return [are.raw_Qs, are.IS_V, are.DR_V, are.TR_V, are.QR_V]\n",
    "    #################################\n",
    "    ray.init()\n",
    "    futures = [one_seed1.remote(j) for j in range(n_gpu * i, n_gpu * (i + 1))]\n",
    "    res = ray.get(futures)\n",
    "    #################################\n",
    "    for j in range(n_gpu):\n",
    "        rec.update(V_true, are_details = res[j])\n",
    "    _ = rec.analyze()\n",
    "    #################################\n",
    "    printR(\"time cost for {}-th rep = {:.1f} mins\".format(i, (now() - a) / 60))\n",
    "    rec.save(\"res/\" + setting)\n",
    "    ray.shutdown()\n",
    "    #################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
